# ğŸ“ Skool Scraper SaaS

Un mini SaaS moderno e intuitivo per lo scraping e l'analisi intelligente di gruppi Skool. Estrae tutto il contenuto da qualsiasi gruppo Skool (lezioni, discussioni, post) e genera riassunti e report dettagliati usando l'AI.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Node](https://img.shields.io/badge/node-%3E%3D18-brightgreen)

## âœ¨ Caratteristiche

- ğŸš€ **Scraping Veloce**: Utilizza Apify per estrarre migliaia di elementi da gruppi Skool
- ğŸ¤– **Analisi AI**: Genera riassunti intelligenti e report dettagliati con OpenAI
- ğŸ“Š **Dashboard Intuitiva**: Interfaccia moderna e facile da usare
- ğŸ’¾ **Storico Completo**: Salva tutti gli scraping e riassunti in un database locale
- ğŸ¯ **Multi-Topic**: Funziona con qualsiasi tipo di gruppo (cucina, marketing, survival, etc.)
- âš¡ **Deploy Facile**: Pronto per il deploy su fly.io senza Docker

## ğŸ“‹ Prerequisiti

- Node.js 18 o superiore
- Account [Apify](https://apify.com/) (per lo scraping)
- API Key [OpenAI](https://platform.openai.com/) (per i riassunti AI)

## ğŸš€ Installazione

### 1. Clona la repository

```bash
git clone https://github.com/maru-mm/skool-scraper.git
cd skool-scraper
```

### 2. Installa le dipendenze

```bash
npm install
```

### 3. Configura le variabili d'ambiente

Crea un file `.env` nella root del progetto:

```env
# Apify API Token (Richiesto)
APIFY_TOKEN=your_apify_token_here

# OpenAI API Key (Richiesto)
OPENAI_API_KEY=your_openai_api_key_here

# Configurazione Server (Opzionale)
PORT=3000
NODE_ENV=development
```

**Come ottenere le API Keys:**

- **Apify Token**: 
  1. Registrati su [apify.com](https://apify.com/)
  2. Vai su Settings â†’ Integrations â†’ API tokens
  3. Crea un nuovo token

- **OpenAI API Key**:
  1. Registrati su [platform.openai.com](https://platform.openai.com/)
  2. Vai su API keys
  3. Crea una nuova chiave segreta

### 4. Crea la cartella per il database

```bash
mkdir data
```

## ğŸ’» Utilizzo

### Sviluppo

Avvia il server di sviluppo (backend + frontend):

```bash
npm run dev
```

- Frontend: http://localhost:5173
- Backend API: http://localhost:3000

### Produzione

Build e avvio in produzione:

```bash
npm run build
npm start
```

## ğŸ“¦ Deploy su fly.io

### 1. Installa fly.io CLI

```bash
# macOS
brew install flyctl

# Altri sistemi: https://fly.io/docs/hands-on/install-flyctl/
```

### 2. Login su fly.io

```bash
fly auth login
```

### 3. Crea il volume per i dati

```bash
fly volumes create data --region fra --size 1
```

### 4. Imposta i secrets

```bash
fly secrets set APIFY_TOKEN=your_apify_token
fly secrets set OPENAI_API_KEY=your_openai_key
```

### 5. Deploy!

```bash
fly deploy
```

La tua app sarÃ  disponibile su `https://tuo-nome-app.fly.dev`

## ğŸ¯ Come Usare

1. **Inserisci l'URL**: Copia l'URL del gruppo Skool che vuoi analizzare
2. **Seleziona le Opzioni**: Scegli la sezione (Classroom, Community, etc.)
3. **Avvia lo Scraping**: Clicca su "Inizia Scraping"
4. **Attendi il Completamento**: Il sistema estrae tutti i dati
5. **Genera il Riassunto**: Clicca su "Genera Riassunto" per l'analisi AI
6. **Visualizza i Risultati**: Leggi il riassunto, i punti chiave e gli insights

## ğŸ“ Struttura del Progetto

```
skool-scraper/
â”œâ”€â”€ server/                 # Backend Node.js
â”‚   â”œâ”€â”€ index.js           # Entry point server
â”‚   â”œâ”€â”€ db/                # Database SQLite
â”‚   â”‚   â””â”€â”€ database.js    # Setup DB
â”‚   â”œâ”€â”€ routes/            # API Routes
â”‚   â”‚   â”œâ”€â”€ scraper.js     # Endpoint scraping
â”‚   â”‚   â”œâ”€â”€ summary.js     # Endpoint AI
â”‚   â”‚   â””â”€â”€ history.js     # Endpoint cronologia
â”‚   â””â”€â”€ services/          # Business logic
â”‚       â”œâ”€â”€ apifyService.js    # Integrazione Apify
â”‚       â””â”€â”€ aiService.js       # Integrazione OpenAI
â”œâ”€â”€ src/                   # Frontend React
â”‚   â”œâ”€â”€ components/        # Componenti UI
â”‚   â”‚   â”œâ”€â”€ Header.jsx
â”‚   â”‚   â”œâ”€â”€ ScraperForm.jsx
â”‚   â”‚   â”œâ”€â”€ StatusDisplay.jsx
â”‚   â”‚   â”œâ”€â”€ SummaryDisplay.jsx
â”‚   â”‚   â””â”€â”€ History.jsx
â”‚   â”œâ”€â”€ App.jsx           # Componente principale
â”‚   â”œâ”€â”€ main.jsx          # Entry point
â”‚   â””â”€â”€ index.css         # Stili globali
â”œâ”€â”€ data/                 # Database SQLite (creato automaticamente)
â”œâ”€â”€ package.json          # Dipendenze
â”œâ”€â”€ vite.config.js        # Configurazione Vite
â”œâ”€â”€ fly.toml              # Configurazione fly.io
â””â”€â”€ README.md             # Questo file
```

## ğŸ› ï¸ API Endpoints

### Scraping

- `POST /api/scraper/start` - Avvia un nuovo scraping
- `GET /api/scraper/status/:scrapeId` - Verifica lo stato
- `GET /api/scraper/items/:scrapeId` - Ottieni i dati scrapati

### AI Summary

- `POST /api/summary/generate/:scrapeId` - Genera un riassunto
- `GET /api/summary/:summaryId` - Ottieni un riassunto
- `POST /api/summary/report/:scrapeId` - Genera un report completo

### History

- `GET /api/history` - Lista tutti gli scraping
- `DELETE /api/history/:scrapeId` - Elimina uno scraping

### Health

- `GET /api/health` - Verifica stato server

## ğŸ”§ Tecnologie Utilizzate

### Backend
- **Node.js** + **Express** - Server e API
- **Apify Client** - Scraping di Skool
- **OpenAI API** - Generazione riassunti
- **JSON File Storage** - Storage semplice e affidabile

### Frontend
- **React 18** - UI Framework
- **Vite** - Build tool ultra-veloce
- **CSS3** - Styling moderno con gradients

### Deploy
- **Fly.io** - Hosting e deploy automatico
- **Docker** - Build ottimizzato multi-stage

## ğŸ’¡ Tips & Best Practices

- **Limiti Apify**: Controlla i limiti del tuo piano Apify
- **Costi OpenAI**: I riassunti usano GPT-4o-mini per ottimizzare i costi
- **Database**: Il database SQLite Ã¨ locale, considera un backup per produzione
- **Rate Limiting**: Implementa rate limiting in produzione per evitare abusi

## ğŸ› Troubleshooting

### Errore "Scraping failed"
- Verifica che il tuo APIFY_TOKEN sia valido
- Controlla che l'URL Skool sia corretto e pubblico

### Errore "Summary generation failed"
- Verifica che la tua OPENAI_API_KEY sia valida
- Controlla di avere crediti disponibili su OpenAI

### Database locked
- Chiudi tutte le connessioni al database
- Riavvia il server

## ğŸ“ TODO / Roadmap

- [ ] Aggiungere supporto per download PDF dei report
- [ ] Implementare autenticazione utenti
- [ ] Aggiungere grafici e statistiche
- [ ] Supporto per scraping multipli in parallelo
- [ ] Integrazione con altri LLM (Claude, Gemini)
- [ ] Export in formato Markdown

## ğŸ¤ Contribuire

Le pull request sono benvenute! Per modifiche importanti, apri prima un issue per discutere i cambiamenti.

## ğŸ“„ Licenza

MIT License - vedi file LICENSE per dettagli

## ğŸ‘¤ Autore

**Maru**
- GitHub: [@maru-mm](https://github.com/maru-mm)

## ğŸ™ Credits

- [Apify](https://apify.com/) per il servizio di scraping
- [OpenAI](https://openai.com/) per l'API GPT
- [Skool](https://skool.com/) per la piattaforma

---

â­ Se questo progetto ti Ã¨ stato utile, lascia una stella su GitHub!

